{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niit-ibm/lt4-pe-lab2/blob/main/pe_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ5U7O4R-rSD"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install git+https://github.com/ibm-granite-community/utils \\\n",
        "    \"langchain_community<0.3.0\" \\\n",
        "    replicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RauRfaO-rSF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import replicate\n",
        "from langchain_community.llms import Replicate\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, HTML\n",
        "from string import Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGHGHb6w-rSG"
      },
      "outputs": [],
      "source": [
        "#Use the utility function to get from environment or prompt\n",
        "replicate_api_token = get_env_var(\"REPLICATE_API_TOKEN\")\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = replicate_api_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Skx7Ydo-rSH"
      },
      "outputs": [],
      "source": [
        "# Model configuration - matching reference implementation\n",
        "MODEL_NAME = \"ibm-granite/granite-3.3-8b-instruct\"\n",
        "MAX_TOKENS = 1024\n",
        "TEMPERATURE = 0.2\n",
        "\n",
        "# Initialize the model\n",
        "llm = Replicate(\n",
        "    model=MODEL_NAME,\n",
        "    model_kwargs={\n",
        "        \"max_tokens\": MAX_TOKENS,\n",
        "        \"temperature\": TEMPERATURE\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"âœ… Model initialized: {MODEL_NAME}\")\n",
        "print(f\"   Max Tokens: {MAX_TOKENS}\")\n",
        "print(f\"   Temperature: {TEMPERATURE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjwJzHpB-rSJ"
      },
      "outputs": [],
      "source": [
        "# Task 3: Draft an initial prompt for a specific project\n",
        "# This is NOT a template yet - it's hard-coded for one specific use case\n",
        "\n",
        "baseline_prompt = \"\"\"Write a concise weekly status summary for the DeltaFin client project.\n",
        "Highlight progress made this week, note any blockers, and outline next steps in a professional\n",
        "tone suitable for a client email.\"\"\"\n",
        "\n",
        "print(\"ðŸ”µ TASK 3: Baseline Prompt (Single-Use)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nPrompt:\")\n",
        "print(baseline_prompt)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Generating output...\\n\")\n",
        "\n",
        "# Generate output using the baseline prompt\n",
        "baseline_output = llm.invoke(baseline_prompt)\n",
        "\n",
        "print(\"Generated Output:\")\n",
        "print(\"-\"*70)\n",
        "print(baseline_output)\n",
        "print(\"-\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MryKI5dP-rSK"
      },
      "outputs": [],
      "source": [
        "# Task 4: Convert the baseline prompt into a reusable template with variables\n",
        "\n",
        "# Using Python's string formatting with named placeholders\n",
        "prompt_template = \"\"\"Write a concise weekly status summary for the {client_name} project.\n",
        "\n",
        "Summarize progress made during {time_period}, note {blockers}, and outline {next_steps}\n",
        "in a {tone} tone suitable for {audience}.\n",
        "\n",
        "Additional context:\n",
        "- Progress: {progress}\n",
        "- Format: {output_format}\n",
        "\"\"\"\n",
        "\n",
        "print(\"ðŸŸ¢ TASK 4: Reusable Prompt Template\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nTemplate with Variables:\")\n",
        "print(\"-\"*70)\n",
        "print(prompt_template)\n",
        "print(\"-\"*70)\n",
        "\n",
        "print(\"\\nâœ… Template created successfully!\")\n",
        "print(\"\\nVariables identified:\")\n",
        "variables = [\"{client_name}\", \"{time_period}\", \"{progress}\", \"{blockers}\",\n",
        "             \"{next_steps}\", \"{tone}\", \"{audience}\", \"{output_format}\"]\n",
        "for var in variables:\n",
        "    print(f\"  â€¢ {var}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test Case 1: DeltaFin Project (Financial Services)"
      ],
      "metadata": {
        "id": "tutDbvz_UEfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feD5QtjX-rSK"
      },
      "outputs": [],
      "source": [
        "# Define variables for Project 1: DeltaFin\n",
        "project1_vars = {\n",
        "    \"client_name\": \"DeltaFin\",\n",
        "    \"time_period\": \"Week 4\",\n",
        "    \"progress\": \"Completed API integration testing and resolved 15 critical bugs\",\n",
        "    \"blockers\": \"testing delays caused by the external vendor's infrastructure issues\",\n",
        "    \"next_steps\": \"finalize the integration plan and begin UAT preparation\",\n",
        "    \"tone\": \"formal\",\n",
        "    \"audience\": \"senior client stakeholders\",\n",
        "    \"output_format\": \"structured paragraph with clear sections\"\n",
        "}\n",
        "\n",
        "# Substitute variables into the template\n",
        "project1_prompt = prompt_template.format(**project1_vars)\n",
        "\n",
        "print(\"ðŸŸ£ TASK 5: Testing Template - Project 1 (DeltaFin)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nVariable Values:\")\n",
        "for key, value in project1_vars.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Generated Prompt:\")\n",
        "print(\"-\"*70)\n",
        "print(project1_prompt)\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Generating output...\\n\")\n",
        "\n",
        "# Generate output\n",
        "project1_output = llm.invoke(project1_prompt)\n",
        "\n",
        "print(\"Generated Status Summary:\")\n",
        "print(\"-\"*70)\n",
        "print(project1_output)\n",
        "print(\"-\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwMSDPBQ-rSL"
      },
      "source": [
        "### Test Case 2: MediTrack Project (Healthcare Technology)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44MOIZjH-rSL"
      },
      "outputs": [],
      "source": [
        "# Define variables for Project 2: MediTrack\n",
        "project2_vars = {\n",
        "    \"client_name\": \"MediTrack\",\n",
        "    \"time_period\": \"Sprint 2\",\n",
        "    \"progress\": \"Successfully deployed the patient data dashboard and completed security audit\",\n",
        "    \"blockers\": \"pending approvals from the compliance team for HIPAA certification\",\n",
        "    \"next_steps\": \"complete the data-mapping activity and prepare for pilot testing\",\n",
        "    \"tone\": \"neutral, business-professional\",\n",
        "    \"audience\": \"internal project sponsors\",\n",
        "    \"output_format\": \"bullet-point list with clear categories\"\n",
        "}\n",
        "\n",
        "# Substitute variables into the template\n",
        "project2_prompt = prompt_template.format(**project2_vars)\n",
        "\n",
        "print(\"ðŸŸ£ TASK 5: Testing Template - Project 2 (MediTrack)\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nVariable Values:\")\n",
        "for key, value in project2_vars.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Generated Prompt:\")\n",
        "print(\"-\"*70)\n",
        "print(project2_prompt)\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Generating output...\\n\")\n",
        "\n",
        "# Generate output\n",
        "project2_output = llm.invoke(project2_prompt)\n",
        "\n",
        "print(\"Generated Status Summary:\")\n",
        "print(\"-\"*70)\n",
        "print(project2_output)\n",
        "print(\"-\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dibHu7J9-rSL"
      },
      "source": [
        "### Task 5: Conclusion\n",
        "\n",
        "**Testing Results:**\n",
        "- âœ… Template produces consistent, high-quality outputs\n",
        "- âœ… Successfully adapts to different contexts\n",
        "- âœ… Maintains appropriate tone for each audience\n",
        "- âœ… Generates properly formatted summaries\n",
        "\n",
        "**Template Benefits:**\n",
        "1. **Time Savings**: Analysts don't rewrite prompts from scratch\n",
        "2. **Consistency**: All outputs follow the same structure\n",
        "3. **Quality**: Professional standards maintained across team\n",
        "4. **Scalability**: Works for unlimited number of projects\n",
        "5. **Flexibility**: Adapts to different tones and audiences\n",
        "\n",
        "**Conclusion:** Your template now produces clear, consistent outputs for any project in your team. You've successfully created a scalable, reusable prompt template that analysts across the organization can use."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}